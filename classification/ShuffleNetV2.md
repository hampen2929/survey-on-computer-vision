# ShuffleNet V2: Practical Guidelines for EfficientCNN Architecture Design

## 概要

NNのアーキテクチャ設計は、ほとんどの場合、計算の複雑さの間接的な指標のFLOPsに基づいてる。しかし速度などの直接的な指標は、実行環境の特性にも依存する。そこで、本研究では実行環境上で直接評価を行うことを提案。

間接メトリック（ＦＬＯＰｓ）と直接メトリック（速度）の間の不一致は、２つの主な理由に起因する。

第一に、速度に大きな影響を与えるいくつかの重要な要因がFLOPsでは考慮されていないことです。そのような要因の一つは、メモリアクセスコスト（MAC）です。このようなコストは、グループ畳み込みのような特定の演算において実行時間の大部分を占めています。このコストは、GPUなどの強力な計算能力を持つデバイスではボトルネックになる可能性があります。ネットワークアーキテクチャ設計の際に、このコストを単純に無視してはいけません。もう一つは並列度である。並列度の高いモデルは、同じFLOP数であれば、並列度の低いモデルよりもはるかに高速になる可能性があります。

第二に、同じFLOPsでもプラットフォームによって実行時間が異なる可能性があります。例えば、初期の研究[20,21,22]では、行列の乗算を高速化するためにテンソル分解が広く使われていましたが、最近の研究[19]では、行列の乗算を高速化するためにテンソル分解が使われています。しかし、最近の研究[19]では、[22]の分解はFLOPを75%削減しているにもかかわらず、GPU上ではさらに遅いことがわかった。この問題を調べたところ、最新のCUDNN[23]ライブラリが3×3 conv用に特別に最適化されているためであることがわかりました。 3×3 convが1×1 convの9倍遅いというのは確かに考えられませんが、3×3 convの方が1×1 convの9倍遅いと考えることができます。

![image](https://user-images.githubusercontent.com/34574033/84583151-7d2d3780-ae30-11ea-954d-44503ed182f2.png)

## 所感

## 参考

## 翻訳

抄録
現在、ニューラルネットワークのアーキテクチャ設計は、ほとんどの場合、計算の複雑さの間接的な指標であるFLOPsに基づいて行われています。しかし、速度などの直接的な指標は、メモリアクセスコストやプラットフォームの特性などの他の要因にも依存します。そこで、本研究では、FLOPsのみを考慮するのではなく、対象となるプラットフォーム上で直接評価を行うことを提案しています。一連の制御実験に基づいて、効率的なネットワーク設計のための実用的なガイドラインを導き出した。その結果、ShuffleNet V2と呼ばれる新しいアーキテクチャが提示された。包括的なアブレーション実験により、我々のモデルが速度と精度のトレードオフの点で最先端であることが確認された。

序論
深層畳み込みニュートラルネットワーク(CNN)のアーキテクチャは長年にわたり進化し、より正確で高速なものになってきている。AlexNet [1]のマイルストーンとなった研究以来，ImageNetの分類精度はVGG [2]，GoogLeNet [3]，ResNet [4,5]，DenseNet [6]，ResNeXt [7]，SE-Net [8]，自動中立アーキテクチャ探索[9,10,11]などの新しい構造によって大幅に改善されてきた．精度の他に、計算の複雑さも重要な考慮事項の一つです。実世界のタスクでは、ターゲットプラットフォーム（例：ハードウェア）やアプリケーションシナリオ（例：自動運転には低レイテンシが必要）によって与えられた限られた計算予算の下で最高の精度を得ることを目的としていることがよくあります。このため、Xception [12]、MobileNet [13]、MobileNet V2 [14]、ShuffleNet [15]、CondenseNet [16]など、軽量なアーキテクチャ設計と速度と精度のトレードオフの改善に向けた一連の研究が進められてきました。これらの研究では，群畳み込みと深さ方向の畳み込みが重要である．計算の複雑さを測定するための指標として，FLOPs1 と呼ばれる浮動小数点演算の数が広く用いられている．しかし，FLOPs は間接的な指標である．FLOPs は間接的な指標であり，近似的なものですが，通常は速度やレイテンシなど，我々が本当に気にしている直接的な指標と同等のものではありません．このような矛盾は、以前の研究[17,18,14,19]でも指摘されています。例えば、MobileNet v2 [14]はNASNET-A [9]よりもはるかに高速ですが、FLOPは同等です。この現象は図1(c)(d)に示されており、類似のFLOPsを持つネットワークでは速度が異なることを示している。したがって、FLOPs を計算複雑度の唯一の指標として使用することは不十分であり、最適でない設計につながる可能性があります。間接メトリック（ＦＬＯＰｓ）と直接メトリック（速度）の間の不一致は、２つの主な理由に起因します。第一に、速度に大きな影響を与えるいくつかの重要な要因がFLOPsでは考慮されていないことです。そのような要因の一つは、メモリアクセスコスト（MAC）です。このようなコストは、グループ畳み込みのような特定の演算において実行時間の大部分を占めています。このコストは、GPUなどの強力な計算能力を持つデバイスではボトルネックになる可能性があります。ネットワークアーキテクチャ設計の際に、このコストを単純に無視してはいけません。もう一つは並列度である。並列度の高いモデルは、同じFLOP数であれば、並列度の低いモデルよりもはるかに高速になる可能性があります。第二に、同じFLOPsでもプラットフォームによって実行時間が異なる可能性があります。例えば、初期の研究[20,21,22]では、行列の乗算を高速化するためにテンソル分解が広く使われていましたが、最近の研究[19]では、行列の乗算を高速化するためにテンソル分解が使われています。しかし、最近の研究[19]では、[22]の分解はFLOPを75%削減しているにもかかわらず、GPU上ではさらに遅いことがわかった。この問題を調べたところ、最新のCUDNN[23]ライブラリが3×3 conv用に特別に最適化されているためであることがわかりました。 3×3 convが1×1 convの9倍遅いというのは確かに考えられませんが、3×3 convの方が1×1 convの9倍遅いと考えることができます。

これらの観察結果から、効果的なネットワークアーキテクチャ設計のためには、2つの原則を考慮すべきであることを提案する。第一に、間接的な指標(例えばFLOPs)ではなく、直接的な指標(例えば速度)を使用すべきである。第二に、このようなメトリックは、ターゲットプラットフォーム上で評価されるべきである。本研究では、この2つの原則に基づき、より効果的なネットワークアーキテクチャを提案する。第2節では、まず、2つの代表的な最先端ネットワークの実行時性能を分析する[15,14]。次に、効率的なネットワーク設計のための4つのガイドラインを導出する。これらのガイドラインはプラットフォームに依存しないが，一連の制御実験を行い，専用のコード最適化を行った2つの異なるプラットフォーム（GPUとARM）で検証し，結論が最新のものであることを確認した．第3節では、ガイドラインに従って、新しいネットワーク構造を設計する。これはShuffleNet[15]に触発されたもので、ShuffleNet V2と呼ばれている。第4節では、両プラットフォーム上での包括的な検証実験を行い、従来のネットワークよりもはるかに高速かつ高精度であることを実証した。図１（ａ）（ｂ）に比較の概要を示す。例えば、40M FLOPsの計算複雑度予算を考えると、ShuffleNet v2は、ShuffleNet v1とMobileNet v2に比べて、それぞれ3.5%と3.7%の精度向上を実現している。

![image](https://user-images.githubusercontent.com/34574033/84583151-7d2d3780-ae30-11ea-954d-44503ed182f2.png)


# Simple yet efficient real-time pose-based action recognition

## 概要
標準的な単眼カメラセンサを用いて、人間を検出し、ポーズを推定し、経時的に追跡し、リアルタイムで行動を認識するパイプラインを実証

![image](https://user-images.githubusercontent.com/34574033/84571799-b635bf80-add0-11ea-8ca8-1cb04d6c166c.png)

![image](https://user-images.githubusercontent.com/34574033/84571806-c51c7200-add0-11ea-9eb1-04c7b6670755.png)

## 所感

こういうシンプルだが精度が出て実行速度が早い研究いい。複数枚画像入力での動作検出のほうが精度が良いが、poseベースのほうが実装がリーズナブル。

## 参考

https://arxiv.org/pdf/1904.09140.pdf

https://github.com/noboevbo/ehpi_action_recognition

## 翻訳

### 抄録

人間と同じ空間を直接共有する自律システムにとって、人間の行動を認識することは重要な課題である。システムはリアルタイムで人間の行動を認識し、評価することができる必要がある。対応するデータ駆動型アルゴリズムを訓練するためには、膨大な量のアノテーションされた訓練データが必要となる。我々は、標準的な単眼カメラセンサを用いて、人間を検出し、ポーズを推定し、経時的に追跡し、リアルタイムで行動を認識するパイプラインを実証した。行動認識のために、人間のポーズをエンコードし、EHPI（Encoded Human Pose Image）と呼ばれる新しいデータ形式に変換し、コンピュータビジョンコミュニティの標準的な手法を用いて分類します。このシンプルな手法により，姿勢に基づく行動検出において，競争力のある最先端の性能を実現し，リアルタイム性能を確保することができます．さらに、自律走行のコンテキストでの使用例を示し、シミュレーションデータを用いて人間の行動を認識するために、このようなシステムをどのように訓練することができるかを示しています。

### はじめに

人間の行動を人間のように理解することが、都市部での自動運転車のような自律走行システムの大きな課題であるというコンセンサスが高まっている[1]。将来的には、自律システムと人間が共用の公共空間で共存することになるだろう。系列センサ技術を用いて世界の状態を確実に推論することは、依然として課題である。私たちが非常に重要だと考えている分野の一つに、人間の行動の検出があります。この分野はまだ未開拓の分野であり、安定して確実に生産的に利用できるシステムはありません。自律システムが人と対話しなければならない分野では、人が自分の身近な環境で正確に何をしているのかという情報を持っていることが非常に重要です。これは、人間との直接の相互作用が行われる場合には特にそうである。人間の行動は非常に動的であるため、行動を正確に予測するだけでなく、リアルタイムに予測することが重要です。アルゴリズムの実行時間の要件に加えて、データ駆動型アルゴリズムでは、膨大な量のトレーニングデータが必要となります。データ取得は通常、データ駆動アルゴリズムの開発における主要な問題の一つであり、我々は、アルゴリズムに十分なデータを提供することが、このアルゴリズムの設計における重要な要素であると考えている。我々は[2]で、コーナーケースを認識するためにシミュレートされたデータを用いてポーズ認識アルゴリズムを訓練できることを示しました。この研究の続きとして、行動検出アルゴリズムの訓練にシミュレーションデータを適用することに大きな可能性があると考えています。シミュレーションされた視覚データから実データへと領域がシフトしているため、我々は視覚センサ情報に直接依存しない姿勢ベースの行動認識アルゴリズムを設計することにしました。この抽象化層を用いることで、シミュレーションデータを用いたアルゴリズムの学習を可能にし、領域移行の問題を克服したいと考えています。これにより、実際のセンサデータを記録したり、アノテーションを行ったりする際に必要な手作業を大幅に省くことができます。私たちのプロジェクトOpen Fusion Platform1は、バレーパーキング機能を持つ自律走行車を開発しています。駐車場の空きスペースを自動的に検索し、自動的にピックアップポイントに戻ることができます。駐車場には歩行者が存在する可能性があるため、歩行者を認識することが重要です。歩行者の純粋な認識に加えて、彼らが何をしているかを認識することも重要です。私たちの使用例では、車両が動いていない限り、彼らは私たちの駐車している車両の前にいることが許されています。歩行者が車両の前にいることを検知している間に車を追い出すためには、歩行者が手を振るジェスチャーで、車の追い出しを許可していることを明確に示さなければならない。このように、歩行者を検出し、さらに歩行者の現在の行動を分類しなければならない。この駐車場の使用例では、アイドル、歩行、手を振っている行動を検出しなければならないことを指定しました。

本研究での貢献は以下の通りです。
1) リアルタイムで2D単眼カメラ画像上で動作する認識パイプライン。これは、物体、人間、そのポーズを検出する機能を含んでいる。人間とその行動を追跡・推定するためのアルゴリズムを開発しました．
2) 最新の性能を持つ体位に基づく行動認識アルゴリズムの開発 
3) シミュレーションデータを用いて行動認識アルゴリズムを改良する方法を示す．
